{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook applies vehicles [**tracking**](#Apply-Tracking) for **a single 8-minute-video** using [pytorch_objectdetecttrack](https://github.com/cfotache/pytorch_objectdetecttrack) with a few minor modifications (e.g. accelerated renewal of tracking after a frame with no detection), shows various [**properties of the trackings**](#Explanatory-Descriptive-Analysis), studies some [**anomalies**](#Invalid-Trackings-Study) in the trackings (most of them relate to the detection & tracking algorithms rather than actual behavior of vehicles), and studies the [**driving speed**](#Driving-Speed-Analysis) of the cars along the video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [**Tracking**](#Apply-Tracking)\n",
    "- [**Explanatory Descriptive Analysis**](#Explanatory-Descriptive-Analysis)\n",
    "- [**Anomalies Study**](#Invalid-Trackings-Study)\n",
    "- [**Driving Speed Analysis**](#Driving-Speed-Analysis)\n",
    "- [**Summary**](#Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, time, datetime, random\n",
    "from pathlib import Path\n",
    "from warnings import warn\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "import pickle as pkl\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from collections import Counter, OrderedDict\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import track_tools as tt\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpl.rcParams.update({'font.size': 14})\n",
    "cmap = plt.get_cmap('tab20b')\n",
    "colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODE = 'save' # 'load' / 'save' / None\n",
    "MAX_FRAMES = np.Inf # np.Inf # limit number of frames to read from video\n",
    "DISPLAY = False # whether to show all frames during the main tracking\n",
    "\n",
    "AREA = (0, 650, -350, -50) # zone in the frame to focus (x1,x2,y1,y2)\n",
    "FPS = 30/8 # frames per second in the input video\n",
    "\n",
    "# Output\n",
    "OUT_PATH = Path('tracking_demo_data')\n",
    "OUT_FILE = OUT_PATH/'20190612_175832.slow.pkl' # '20190612_175832.slow.pkl' / 'tmp.pkl'\n",
    "\n",
    "# Input\n",
    "DATA = Path(r'D:\\Media\\Videos\\Ayalon') # path of videos\n",
    "# videopath = str(DATA/'20190622_124116.mp4') # video with very bad detections\n",
    "# videopath = str(DATA/'20190703_163050_slipping_protest.2.mp4') # video with sparse & fast traffic\n",
    "videopath = str(DATA/'20190612_175832.mp4') # video with dense & slow traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == 'load':\n",
    "    \n",
    "    with open(OUT_FILE,'rb') as f:\n",
    "        dct = pkl.load(f)\n",
    "    X = dct['X']\n",
    "    Y = dct['Y']\n",
    "    S = dct['S']\n",
    "    C = dct['C']\n",
    "    W = dct['W'] if 'W' in dct else AREA[1]-AREA[0]\n",
    "    H = dct['H'] if 'H' in dct else AREA[3]-AREA[2]\n",
    "    \n",
    "else:\n",
    "\n",
    "    %pylab inline\n",
    "    X,Y,S,C,other_objs,W,H = tt.analyze_video(videopath, area=AREA, MAX_FRAMES=MAX_FRAMES, DISPLAY=DISPLAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, slope = tt.summarize_video(X,Y,S,C,W,H,FPS)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if MODE == 'save':\n",
    "    with open(OUT_FILE,'wb') as f:\n",
    "        pkl.dump({'X':X, 'Y':Y, 'S':S, 'C':C, 'W':W, 'H':H, 'others':other_objs, 'df':df}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanatory Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpl.rcParams.update({'font.size': 13})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show all trackings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.title(f'{X.shape[1]:d} cars track')\n",
    "tt.set_track_figure(W,H)\n",
    "\n",
    "for car in X.columns:\n",
    "    tt.plot_track(X,Y,car)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show distributions of data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variables_groups_to_compare = (\n",
    "    ('consistent_class','consistent_xy_nas','valid_size','valid_x_dir','valid_y_dir'),\n",
    "    ('continuous_track','long_path'),\n",
    "    ('min_x','max_x'),\n",
    "    ('min_y','max_y'),\n",
    "    ('avg_size','max_size'),\n",
    "    ('v','abs_v'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = int(np.ceil(5/2))\n",
    "_, axs = plt.subplots(n_rows, 2, figsize=(16,n_rows*4))\n",
    "\n",
    "for i, cols in enumerate(variables_groups_to_compare):\n",
    "    ax = plt.subplot(n_rows, 2, i+1)\n",
    "    tt.qplots(df.loc[:,cols])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if not col in [c for grp in variables_groups_to_compare for c in grp]]\n",
    "n_rows = int(np.ceil(len(cols)/4))\n",
    "_, axs = plt.subplots(n_rows, 4, figsize=(16,n_rows*4))\n",
    "\n",
    "for i,c in enumerate(cols):\n",
    "    ax = plt.subplot(n_rows, 4, i+1)\n",
    "    if type(df[c][0]) is str:\n",
    "        df[c].value_counts().plot('bar')\n",
    "        ax.set_xlabel(c)\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.grid()\n",
    "    else:\n",
    "        tt.qplot(df[c], ax=ax, ylab=c, logscale=False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show relations between a few pairs of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = (\n",
    "    ('x_path_rel','neg_x_motion'),\n",
    "    ('x_path_rel','neg_y_motion'),\n",
    "    ('x_path_rel','v'),\n",
    "    ('min_x','max_x'),\n",
    "    ('t0','v'),\n",
    "    ('t0','road_perpendicularity'),\n",
    ")\n",
    "\n",
    "n_rows = int(np.ceil(len(pairs)/2))\n",
    "_, axs = plt.subplots(n_rows, 2, figsize=(16,n_rows*5))\n",
    "\n",
    "for i,(c1,c2) in enumerate(pairs):\n",
    "    ax = plt.subplot(n_rows, 2, i+1)\n",
    "    tt.boxplot_per_bucket(df[c1], df[c2], ax=ax, xlab=c1, ylab=c2, logscale=False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invalid Trackings Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validations = ('consistent_class','consistent_xy_nas','valid_x_dir','valid_y_dir','valid_size','long_path','continuous_track')\n",
    "n_samples = 4\n",
    "\n",
    "all_valid = [val for val in validations if df[val].all()]\n",
    "print('Valid fields: ', ', '.join(all_valid))\n",
    "\n",
    "validations = [val for val in validations if val not in all_valid]\n",
    "n_rows = int(np.ceil(len(validations)/2))\n",
    "_, axs = plt.subplots(n_rows, 2, figsize=(16,n_rows*4))\n",
    "\n",
    "for i,val in enumerate(validations):\n",
    "    ax = plt.subplot(n_rows, 2, i+1)\n",
    "    tt.set_track_figure(W,H,ax)\n",
    "    \n",
    "    cars = df.index[np.logical_not(df[val])]\n",
    "    n_bad = len(cars)\n",
    "    if n_samples < len(cars):\n",
    "        cars = np.random.choice(cars, n_samples, replace=False)\n",
    "    \n",
    "    for car in cars:\n",
    "        tt.plot_track(X,Y,car,ax)\n",
    "    ax.set_title(f'Not {val:s} (total: {n_bad:d}/{df.shape[0]:d} = {100*n_bad/df.shape[0]:.0f}%)')\n",
    "    ax.legend()\n",
    "    \n",
    "    print(f'\\n{val:s} overlaps (all={np.sum(np.logical_not(df[val])):d}):')\n",
    "    print({val2: np.sum(np.logical_not(df.loc[np.logical_not(df[val]),val2])) for val2 in validations if val2!=val})\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert(False), \"Change IDs below and go on\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Large\" cars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.record_frame(videopath, X, Y, '1100', frm=1, self_track=3,\n",
    "                display=True, boxes=True, to_save=OUT_PATH/'large_car', TITLE='\"Large car\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative motion along y-axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt.record_video(videopath, X, Y, '1568', self_track=8, display=False, to_save=OUT_PATH/'neg_y')\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.record_frame(videopath, X, Y, '1568', frm=25, self_track=8, display=True, to_save=OUT_PATH/'neg_y',\n",
    "                TITLE='Invalid motion direction in Y-axis - simply detection confusion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motion perpendicular to the road:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "for i in range(-10,91,20):\n",
    "    plt.plot(np.linspace(0, W, 100), slope*np.linspace(0, W, 100) + i, 'k--', alpha=0.5)\n",
    "\n",
    "tt.set_track_figure(W,H)\n",
    "car = np.random.choice(df.index[df.perpendicular_range>30])\n",
    "tt.plot_track(X,Y,car)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tt.record_frame(videopath, X, Y, '5120', frm=15, self_track=4, display=False, to_save=OUT_PATH/'perp1a')\n",
    "tt.record_frame(videopath, X, Y, '5120', frm=19, self_track=4, display=True, to_save=OUT_PATH/'perp1b',\n",
    "               TITLE='Motion perpendicular to road - simply detection confusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt.record_video(videopath, X, Y, '5120', self_track=4, display=False, to_save=OUT_PATH/'perp2')\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.record_video(videopath, X, Y, '82', self_track=1, extra_frames=30, display=True, to_save=OUT_PATH/'short')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driving Speed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df.loc[:,['consistent_class','consistent_xy_nas','valid_x_dir','valid_y_dir',\n",
    "                'valid_size','long_path']].all(axis=1)\n",
    "\n",
    "print(f'Valid tracks:\\t{ids.sum()}/{len(ids)} ({100*ids.mean():.0f}%)')\n",
    "\n",
    "_, axs = plt.subplots(2,2, figsize=(16,10))\n",
    "tt.qplot(df.v[ids], ylab=f'Speed (avg = {df.v[ids].mean():.0f})', ax=axs[0,0])\n",
    "tt.boxplot_per_bucket(df.t0[ids], df.v[ids], n_buckets=8, xlab='Time [s]', ylab='Speed [pixels / s]', ax=axs[1,0])\n",
    "tt.boxplot_per_bucket(df.road_perpendicularity[ids], df.v[ids],\n",
    "                      xlab='Line [arbitrary units]', ylab='Speed [pixels / s]', ax=axs[1,1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df.loc[:,['consistent_class','consistent_xy_nas','valid_x_dir','valid_y_dir',\n",
    "                'valid_size','long_path']].all(axis=1)\n",
    "ids = np.logical_and(ids, df.road_perpendicularity<29)\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "tt.boxplot_per_bucket(df.t0[ids], df.v[ids], n_buckets=530//10, xlab='Time [s]', ylab='Average speed (right only) [pixels / s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = list(np.arange(10, df.t0.max()-20, 1/FPS))\n",
    "decay = 10 # 1/e factor every \"decay\" seconds\n",
    "ws = [np.exp(-np.abs(df[ids].t0-t)/decay) for t in times]\n",
    "rolling_speed = [np.sum(w*df[ids].v)/np.sum(w) for w in ws]\n",
    "\n",
    "_, axs = plt.subplots(1,1,figsize=(16,4))\n",
    "ax = axs\n",
    "ax.plot(times, rolling_speed)\n",
    "ax.set_xlabel('Time [s]')\n",
    "ax.set_ylabel('Average speed (right only) [pixels / s]')\n",
    "ax.set_ylim((0,None))\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df.loc[:,['consistent_class','consistent_xy_nas','valid_x_dir','valid_y_dir',\n",
    "                'valid_size','long_path']].all(axis=1)\n",
    "\n",
    "fastest = df[ids].v.argmax()\n",
    "slowest = df[ids].v.argmin()\n",
    "\n",
    "tt.record_video(videopath, X, Y, fastest, display=False, to_save=OUT_PATH/'fastest')\n",
    "tt.record_video(videopath, X, Y, slowest, display=False, to_save=OUT_PATH/'slowest')\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = fastest\n",
    "fast_speeds = np.power(np.power(X[car][X[car].notnull()].diff()[1:],2) + np.power(Y[car][Y[car].notnull()].diff()[1:],2), 0.5) /\\\n",
    "              np.diff(np.array(X.index[X[car].notnull()]))\n",
    "\n",
    "car = slowest\n",
    "slow_speeds = np.power(np.power(X[car][X[car].notnull()].diff()[1:],2) + np.power(Y[car][Y[car].notnull()].diff()[1:],2), 0.5) /\\\n",
    "              np.diff(np.array(X.index[X[car].notnull()]))\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.hist(list(fast_speeds), label='Fastest car')\n",
    "plt.hist(list(slow_speeds), label='Slowest car')\n",
    "plt.xlabel('Speed [pixels / s]')\n",
    "plt.ylabel('Number of frames')\n",
    "plt.title('Histograms of speeds of a single car')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Anomalous trackings\n",
    "\n",
    "The following phenomena were studied in the tracking data of the video `20190612_175832.mp4`, which produced convenient quality (bright illumination with no significant glass window reflections) and moderately crowded traffic.\n",
    "\n",
    "| Phenomenon | Estimated frequency | Estimated reasons | Solution |\n",
    "| --- | --- | --- | --- |\n",
    "| **Vehicles are not detected** | 40-80% of the vehicles in a frame are not detected | Apparently mainly due to being small and crowded | [**TODO**] Try to decrease the boxes of YOLO? Try to apply some dedicated additional learning somehow? |\n",
    "| **Very short paths** (< 30% of the observed road) | 50% of tracks | mis-detection for more than a single frame (often due to presence of a street light pole) causes loss of tracking; in addition, few short paths correspond to fake detections | Since the motion is quite predictable and objects cannot disappear behind anything in the middle of a frame, the number of permitted frames without detection was increased from 1 to 3, reducing total tracks from 1410 to 1211 and short paths from 56% to 45%. Further increase of no-detection frames did not help. |\n",
    "| **Incontinuous track -> missing frames in paths** | 33% of tracks | Few frames are missing due to mis-detections; others are missing because [SORT](https://github.com/abewley/sort) requires several detections in a row before it renews the tracking | Editing SORT code to renew tracking immediately minimized the loss of information due to frames with missing detection. |\n",
    "| **Very large car size** | 3% of tracks | Fake detection: a whole section of road is classified as \"car\" | Filtering out vehicles larger than 6 times the median removed the fake detections of this kind. |\n",
    "| **Motion against road direction** | 4% of tracks | Either fake detections (see \"very large car size\" above) or short path with nearly-standing motion | Filtering out large cars and short paths solved most of the problem. |\n",
    "| **Large motion in perpendicular to road** | 2% of tracks | Tracking-confusions (different vehicles are associated with the same object-ID) - and NOT actual line-transitions of cars | The noise model of Kalman filter (```Q```) could be generalized to express smaller uncertainty in the direction perpendicular to the motion; however, since the phenomenon is quite rare, and since improvement of detection is planned anyway, this is out of the scope of the project. Note that by simply filtering these events out, we would give up on detection of line-transitions. |\n",
    "\n",
    "\n",
    "### Speed analysis\n",
    "\n",
    "- Speed varies between **lines**. In particular, the rightest line is very slow.\n",
    "- Speed varies a lot over **time**, without any clear periodicity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai v1",
   "language": "python",
   "name": "fastai_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
